package main

import (
	"github.com/rs/zerolog"
	"github.com/rs/zerolog/log"
	_ "net/http/pprof"
	"runtime"
	"time"
	"webapp/internal/kafka"
	"webapp/internal/processor"
)

func main() {
	// Use the below goroutine to profile the application
	// go tool pprof http://localhost:6060/debug/pprof/heap
	//go func() {
	//	log.Print(http.ListenAndServe("localhost:6060", nil))
	//}()
	zerolog.TimeFieldFormat = time.RFC3339
	//zerolog.SetGlobalLevel(zerolog.InfoLevel)
	//file, err := os.Create("log.txt")
	//if err != nil {
	//	log.Fatal().Err(err).Msg("Failed to create log file")
	//}
	//defer file.Close()

	// Configure zerolog to write to the file
	//log.Logger = log.Output(zerolog.ConsoleWriter{Out: file, TimeFormat: time.RFC3339})
	runtime.GOMAXPROCS(runtime.NumCPU())

	//kafkaBootstrapServers := os.Getenv("KAFKA_BOOTSTRAP_SERVERS")
	//brokers := strings.Split(kafkaBootstrapServers, ",")
	brokers := []string{"localhost:8082", "localhost:61231"}
	producer, err := kafka.NewProducer(brokers)
	if err != nil {
		log.Error().Msgf("error creating producer: %v", err)
		return
	}
	proc := processor.NewProcessor(&producer)
	proc.DownloadCVERecords()
	log.Print("CVE records downloaded successfully")
	log.Print("Starting read records")
	err = proc.ReadRecords()
	if err != nil {
		log.Error().Msg("error reading records: " + err.Error())
		return
	}

	log.Print("Records read successfully")

	for {
		time.Sleep(10 * time.Second)
	}
}
