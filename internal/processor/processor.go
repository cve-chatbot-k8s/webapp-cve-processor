package processor

import (
	"archive/zip"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"webapp/internal/kafka"

	_ "github.com/rs/zerolog"
	"github.com/rs/zerolog/log"
)

type Processor struct {
	producer kafka.Service
	counter  int64
	wg       sync.WaitGroup
	done     chan struct{}
	once     sync.Once // Ensures the done channel is only closed once
}

func NewProcessor(producer kafka.Service) *Processor {
	return &Processor{
		producer: producer,
		done:     make(chan struct{}),
	}
}

func (p *Processor) Done() <-chan struct{} {
	return p.done
}

func (p *Processor) DownloadCVERecords() {
	log.Print("Downloading CVE records")
	cveURL := os.Getenv("CVE_URL")
	deltaURL := os.Getenv("DELTA_CVE_URL")

	if cveURL == "" && deltaURL == "" {
		log.Fatal().Msg("CVE URL and Delta CVE URL are not set")
		return
	}

	if cveURL != "" {
		p.downloadAndProcessCVE(cveURL, "cvelistV5.zip", "internal/data/cvelistV5-main", "internal/data/cvelistV5-main/cves")
	} else if deltaURL != "" {
		p.downloadAndProcessCVE(deltaURL, "2024-07-24_delta_CVEs_at_1400Z.zip", "internal/data/deltaCves", "internal/data/deltaCves")
	}
}

func (p *Processor) downloadAndProcessCVE(url, zipFileName, unzipDir, cveDir string) {
	zipFilePath := filepath.Join(unzipDir, zipFileName)

	// Check if the directory already exists
	if _, err := os.Stat(cveDir); !os.IsNotExist(err) {
		log.Printf("CVE records already downloaded in %s.", cveDir)
		return
	}

	// Download the CVE Records
	resp, err := http.Get(url)
	if err != nil {
		log.Fatal().Msgf("Unable to download the CVE records with error : %s", err.Error())
		return
	}
	defer resp.Body.Close()

	// Ensure the directory exists
	dir := filepath.Dir(zipFilePath)
	if _, err := os.Stat(dir); os.IsNotExist(err) {
		err := os.MkdirAll(dir, 0755)
		if err != nil {
			log.Fatal().Msgf("Unable to create directory: %s", err)
			return
		}
	}

	// Create a new file
	out, err := os.Create(zipFilePath)
	if err != nil {
		panic(err)
	}
	defer out.Close()

	// Write the body to file
	_, err = io.Copy(out, resp.Body)
	if err != nil {
		panic(err)
	}

	// Open the zip file
	r, err := zip.OpenReader(zipFilePath)
	if err != nil {
		panic(err)
	}
	defer r.Close()

	// Unzip the file
	for _, f := range r.File {
		fpath := filepath.Join(unzipDir, f.Name)

		if f.FileInfo().IsDir() {
			os.MkdirAll(fpath, os.ModePerm)
			continue
		}

		if err = os.MkdirAll(filepath.Dir(fpath), os.ModePerm); err != nil {
			panic(err)
		}

		outFile, err := os.OpenFile(fpath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, f.Mode())
		if err != nil {
			panic(err)
		}

		rc, err := f.Open()
		if err != nil {
			panic(err)
		}

		_, err = io.Copy(outFile, rc)

		outFile.Close()
		rc.Close()

		if err != nil {
			panic(err)
		}
	}
}

type DataPartition struct {
	Partition int32
	Data      []byte
}

func (p *Processor) ReadRecords() error {
	cveDir := os.Getenv("CVE_DIR")
	deltaCveDir := os.Getenv("DELTA_CVE_DIR")

	if cveDir == "" && deltaCveDir == "" {
		log.Fatal().Msg("CVE_DIR and DELTA_CVE_DIR are not set")
		return nil
	}

	dataChan := make(chan DataPartition, 500)
	partitionCount := 10

	// Start a goroutine to produce records
	p.wg.Add(1)
	go func(producer kafka.Service) {
		defer p.wg.Done() // Mark the main goroutine as done when this function returns
		for data := range dataChan {
			err := producer.ProduceCveRecord("cve", data.Data, strconv.FormatInt(atomic.AddInt64(&p.counter, 1), 10), data.Partition)
			if err != nil {
				log.Error().Msgf("error producing record: %v", err)
			}
			// log.Print("Produced a record")
			p.wg.Done() // Mark each record as done
		}
		p.once.Do(func() {
			close(p.done) // Ensure the done channel is only closed once
		})
	}(p.producer)

	readDir := func(dir string) error {
		counter := 0
		err := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return err
			}

			if !info.IsDir() && strings.HasSuffix(info.Name(), ".json") && strings.HasPrefix(info.Name(), "CVE") {
				data, err := os.ReadFile(path)
				if err != nil {
					log.Printf("error reading file: %v\n", err)
					return err
				}
				partition := int32(counter % partitionCount)
				p.wg.Add(1) // Add each record to the WaitGroup
				dataChan <- DataPartition{
					Partition: partition,
					Data:      data,
				}
				counter++
			}
			return nil
		})
		return err
	}

	if cveDir != "" {
		if err := readDir(cveDir); err != nil {
			log.Printf("error walking the path %v: %v\n", cveDir, err)
		}
	}
	if deltaCveDir != "" {
		if err := readDir(deltaCveDir); err != nil {
			log.Printf("error walking the path %v: %v\n", deltaCveDir, err)
		}
	}

	close(dataChan) // Close the data channel to signal no more data
	p.wg.Wait()     // Wait for all goroutines to finish

	// log.Print("All records have been read and processed successfully")
	return nil
}

func (p *Processor) ProduceRecord(producer kafka.Service, data []byte, partition int32) error {
	id := atomic.AddInt64(&p.counter, 1)
	topic := os.Getenv("KAFKA_TOPIC")
	producer.ProduceCveRecord(topic, data, strconv.FormatInt(id, 10), partition)
	return nil
}

func (p *Processor) Shutdown() {
	log.Print("Shutting down processor")
	p.once.Do(func() {
		close(p.done)
	})
	p.wg.Wait()
}
