package kafka

import (
	"context"
	"github.com/IBM/sarama"
	_ "github.com/rs/zerolog"
	"github.com/rs/zerolog/log"
	"time"
)

type Service interface {
	ProduceCveRecord(topic string, value []byte, key string, partition int32) error
	HandleErrors(ctx context.Context)
}

type Producer struct {
	producer sarama.AsyncProducer
}

func NewProducer(brokers []string) (Producer, error) {
	config := sarama.NewConfig()
	config.Producer.Return.Successes = true
	config.Producer.Return.Errors = true
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.ChannelBufferSize = 100000
	config.Net.MaxOpenRequests = 250
	config.Metadata.AllowAutoTopicCreation = false
	config.Producer.Flush.Messages = 1000
	config.Producer.Flush.Frequency = 50 * time.Millisecond

	producer, err := sarama.NewAsyncProducer(brokers, config)
	if err != nil {
		return Producer{
			producer: nil,
		}, err
	}

	return Producer{
		producer: producer,
	}, nil
}

// ProduceCveRecord produces a record to the specified topic.
func (p *Producer) ProduceCveRecord(topic string, value []byte, key string, partition int32) error {
	msg := &sarama.ProducerMessage{
		Topic:     topic,
		Partition: partition,
		Value:     sarama.ByteEncoder(value),
		Key:       sarama.ByteEncoder(key),
	}
	p.producer.Input() <- msg

	return nil
}

func (p *Producer) HandleErrors(ctx context.Context) {
	for {
		select {
		case err := <-p.producer.Errors():
			log.Error().Msgf("error producing message: %v", err)
		case <-ctx.Done():
			log.Info().Msg("Shutting down error handler")
			return
		}
	}
}
