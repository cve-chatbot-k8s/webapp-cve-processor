package kafka

import (
	"context"
	"github.com/IBM/sarama"
	_ "github.com/rs/zerolog"
	"github.com/rs/zerolog/log"
	"time"
)

type Service interface {
	ProduceCveRecord(topic string, value []byte, key string, partition int32) error
	HandleErrors(ctx context.Context)
}

type Producer struct {
	producer sarama.AsyncProducer
}

func NewProducer(brokers []string) (Producer, error) {
	config := sarama.NewConfig()
	config.Producer.Return.Successes = true
	config.Producer.Return.Errors = true
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.ChannelBufferSize = 10000
	config.Net.MaxOpenRequests = 250
	config.Metadata.AllowAutoTopicCreation = false
	config.Producer.Flush.Messages = 500
	config.Producer.Flush.Frequency = 1000 * time.Millisecond

	producer, err := sarama.NewAsyncProducer(brokers, config)
	if err != nil {
		return Producer{
			producer: nil,
		}, err
	}

	return Producer{
		producer: producer,
	}, nil
}

// ProduceCveRecord produces a record to the specified topic.
func (p *Producer) ProduceCveRecord(topic string, value []byte, key string, partition int32) error {
	msg := &sarama.ProducerMessage{
		Topic:     topic,
		Partition: partition,
		Value:     sarama.ByteEncoder(value),
		Key:       sarama.ByteEncoder(key),
	}
	p.producer.Input() <- msg

	return nil
}

func (p *Producer) HandleErrors(ctx context.Context) {
	messageCount := 0
	for {
		select {
		case success := <-p.producer.Successes():
			messageCount++
			log.Info().Msgf("Message successfully produced to topic %s on partition %d. Total messages produced: %d", success.Topic, success.Partition, messageCount)
		case err := <-p.producer.Errors():
			log.Error().Msgf("Error producing message: %v", err)
		case <-ctx.Done():
			log.Info().Msg("Shutting down producer event handler")
			return
		}
	}
}
